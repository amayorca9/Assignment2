{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d95a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2c89fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/anu/Library/CloudStorage/GoogleDrive-varsha.sethuraman@googlemail.com/My Drive/Varsha/Varsha Factory Reset/Canada/Modules/SDA 250 /Code/assignment_2/SFU_Review_Corpus_Raw'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68e32bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_books=os.path.join(os.getcwd(),'BOOKS')\n",
    "data_folder_car=os.path.join(os.getcwd(),'CARS')\n",
    "data_folder_comp=os.path.join(os.getcwd(),'COMPUTERS')\n",
    "data_folder_cook=os.path.join(os.getcwd(),'COOKWARE')\n",
    "data_folder_hotel=os.path.join(os.getcwd(),'HOTELS')\n",
    "data_folder_movies=os.path.join(os.getcwd(),'MOVIES')\n",
    "data_folder_music=os.path.join(os.getcwd(),'MUSIC')\n",
    "data_folder_phones=os.path.join(os.getcwd(),'PHONES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d63fb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/anu/Library/CloudStorage/GoogleDrive-varsha.sethuraman@googlemail.com/My Drive/Varsha/Varsha Factory Reset/Canada/Modules/SDA 250 /Code/assignment_2/SFU_Review_Corpus_Raw/BOOKS'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc584cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/Users/anu/Library/CloudStorage/GoogleDrive-varsha.sethuraman@googlemail.com/My Drive/Varsha/Varsha Factory Reset/Canada/Modules/SDA 250 /Code/assignment_2/SFU_Review_Corpus_Raw/BOOKS',\n",
       "  [],\n",
       "  ['no11.txt',\n",
       "   'no10.txt',\n",
       "   'no12.txt',\n",
       "   'no13.txt',\n",
       "   'no17.txt',\n",
       "   'no16.txt',\n",
       "   'no14.txt',\n",
       "   'no15.txt',\n",
       "   'yes7.txt',\n",
       "   'yes25.txt',\n",
       "   'yes19.txt',\n",
       "   'yes18.txt',\n",
       "   'yes24.txt',\n",
       "   'yes6.txt',\n",
       "   'yes4.txt',\n",
       "   'no8.txt',\n",
       "   'no9.txt',\n",
       "   'yes5.txt',\n",
       "   'yes1.txt',\n",
       "   'yes23.txt',\n",
       "   'yes22.txt',\n",
       "   'yes2.txt',\n",
       "   'yes20.txt',\n",
       "   'yes21.txt',\n",
       "   'yes3.txt',\n",
       "   'no2.txt',\n",
       "   'yes10.txt',\n",
       "   'yes11.txt',\n",
       "   'no3.txt',\n",
       "   'no1.txt',\n",
       "   'yes13.txt',\n",
       "   'yes12.txt',\n",
       "   'yes8.txt',\n",
       "   'no4.txt',\n",
       "   'yes16.txt',\n",
       "   'yes17.txt',\n",
       "   'no5.txt',\n",
       "   'yes9.txt',\n",
       "   'no7.txt',\n",
       "   'yes15.txt',\n",
       "   'yes14.txt',\n",
       "   'no6.txt',\n",
       "   'no24.txt',\n",
       "   'no18.txt',\n",
       "   'no19.txt',\n",
       "   'no25.txt',\n",
       "   'no22.txt',\n",
       "   'no23.txt',\n",
       "   'no21.txt',\n",
       "   'no20.txt'])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(os.walk(data_folder_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adee3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_books = []\n",
    "for root, folders, files in os.walk(data_folder_books):\n",
    "    for file in files:\n",
    "        path = os.path.join(root, file)\n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8') as inf:\n",
    "                file_content = inf.read()\n",
    "                data_books.append(file_content)\n",
    "        except UnicodeDecodeError:\n",
    "            # If decoding with utf-8 fails, attempt decoding with latin-1\n",
    "            with open(path, 'r', encoding='latin-1') as inf:\n",
    "                file_content = inf.read()\n",
    "                data_books.append(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82cec086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(data_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24a18e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cars = []\n",
    "for root, folders, files in os.walk(data_folder_car):\n",
    "    for file in files:\n",
    "        path = os.path.join(root, file)\n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8') as inf:\n",
    "                file_content = inf.read()\n",
    "                data_cars.append(file_content)\n",
    "        except UnicodeDecodeError:\n",
    "            # If decoding with utf-8 fails, attempt decoding with latin-1\n",
    "            with open(path, 'r', encoding='latin-1') as inf:\n",
    "                file_content = inf.read()\n",
    "                data_cars.append(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3f9c310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(data_cars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ca72060",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cook = []\n",
    "for root, folders, files in os.walk(data_folder_cook):\n",
    "    for file in files:\n",
    "        path = os.path.join(root, file)\n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8') as inf:\n",
    "                file_content = inf.read()\n",
    "                data_cook.append(file_content)\n",
    "        except UnicodeDecodeError:\n",
    "            # If decoding with utf-8 fails, attempt decoding with latin-1\n",
    "            with open(path, 'r', encoding='latin-1') as inf:\n",
    "                file_content = inf.read()\n",
    "                data_cook.append(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b752144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "data_comps = []\n",
    "for root, folders, files in os.walk(data_folder_comp):\n",
    "    for file in files:\n",
    "        path = os.path.join(root, file)\n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8') as inf:\n",
    "                file_content = inf.read()\n",
    "                data_comps.append(file_content)\n",
    "        except UnicodeDecodeError:\n",
    "            # If decoding with utf-8 fails, attempt decoding with latin-1\n",
    "            with open(path, 'r', encoding='latin-1') as inf:\n",
    "                file_content = inf.read()\n",
    "                data_comps.append(file_content)\n",
    "print(len(data_comps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d187bf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "data_hotel = []\n",
    "for root, folders, files in os.walk(data_folder_hotel):\n",
    "    for file in files:\n",
    "        path = os.path.join(root, file)\n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8') as inf:\n",
    "                file_content = inf.read()\n",
    "                data_hotel.append(file_content)\n",
    "        except UnicodeDecodeError:\n",
    "            # If decoding with utf-8 fails, attempt decoding with latin-1\n",
    "            with open(path, 'r', encoding='latin-1') as inf:\n",
    "                file_content = inf.read()\n",
    "                data_hotel.append(file_content)\n",
    "print(len(data_hotel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aeaaec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "data_movie = []\n",
    "for root, folders, files in os.walk(data_folder_movies):\n",
    "    for file in files:\n",
    "        path = os.path.join(root, file)\n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8') as inf:\n",
    "                file_content = inf.read()\n",
    "                data_movie.append(file_content)\n",
    "        except UnicodeDecodeError:\n",
    "            # If decoding with utf-8 fails, attempt decoding with latin-1\n",
    "            with open(path, 'r', encoding='latin-1') as inf:\n",
    "                file_content = inf.read()\n",
    "                data_movie.append(file_content)\n",
    "print(len(data_hotel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de0a0654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "data_music = []\n",
    "for root, folders, files in os.walk(data_folder_music):\n",
    "    for file in files:\n",
    "        path = os.path.join(root, file)\n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8') as inf:\n",
    "                file_content = inf.read()\n",
    "                data_music.append(file_content)\n",
    "        except UnicodeDecodeError:\n",
    "            # If decoding with utf-8 fails, attempt decoding with latin-1\n",
    "            with open(path, 'r', encoding='latin-1') as inf:\n",
    "                file_content = inf.read()\n",
    "                data_music.append(file_content)\n",
    "print(len(data_hotel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbd4246e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "data_phone = []\n",
    "for root, folders, files in os.walk(data_folder_phones):\n",
    "    for file in files:\n",
    "        path = os.path.join(root, file)\n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8') as inf:\n",
    "                file_content = inf.read()\n",
    "                data_phone.append(file_content)\n",
    "        except UnicodeDecodeError:\n",
    "            # If decoding with utf-8 fails, attempt decoding with latin-1\n",
    "            with open(path, 'r', encoding='latin-1') as inf:\n",
    "                file_content = inf.read()\n",
    "                data_phone.append(file_content)\n",
    "print(len(data_hotel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed915a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30903d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : 0.631\n",
      "text : 0.2299\n",
      "text : 0.9665\n",
      "text : -0.5984\n",
      "text : 0.9958\n",
      "text : -0.3318\n",
      "text : -0.9841\n",
      "text : -0.9969\n",
      "text : 0.8594\n",
      "text : -0.294\n",
      "text : -0.0557\n",
      "text : -0.9547\n",
      "text : -0.3298\n",
      "text : -0.9914\n",
      "text : 0.9984\n",
      "text : 0.0716\n",
      "text : -0.8481\n",
      "text : 0.976\n",
      "text : 0.9938\n",
      "text : 0.995\n",
      "text : 0.9746\n",
      "text : 0.889\n",
      "text : -0.946\n",
      "text : 0.992\n",
      "text : 0.9121\n",
      "text : 0.9995\n",
      "text : 0.9348\n",
      "text : 0.9655\n",
      "text : 0.9696\n",
      "text : -0.8149\n",
      "text : 0.9237\n",
      "text : 0.9909\n",
      "text : 0.7592\n",
      "text : 0.9949\n",
      "text : 0.9942\n",
      "text : 0.3409\n",
      "text : 0.9723\n",
      "text : 0.9931\n",
      "text : 0.9319\n",
      "text : 0.693\n",
      "text : -0.6696\n",
      "text : 0.9769\n",
      "text : -0.9963\n",
      "text : 0.6917\n",
      "text : -0.9979\n",
      "text : 0.9287\n",
      "text : -0.9425\n",
      "text : -0.9805\n",
      "text : 0.0835\n",
      "text : 0.7183\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Assuming 'data' contains your list of text data\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "for sentence in data_books:\n",
    "    sentiment_scores = sia.polarity_scores(sentence)\n",
    "    # The 'compound' score can help determine overall sentiment\n",
    "    print(\"text\", \":\", sentiment_scores['compound'])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1adb1f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from nltk.sentiment import SentimentIntensityAnalyzer\\n\\n# Assuming \\'data\\' contains your list of text data\\nsia = SentimentIntensityAnalyzer()\\nm={}\\n\\ncount=0\\nfor sentence in data_books:\\n    count+=1\\n    sentiment_scores = sia.polarity_scores(sentence)\\n    # The \\'compound\\' score can help determine overall sentiment\\n    m[sentence]=sentiment_scores\\n    print(list(os.walk(data_folder_books[count])), \":\", sentiment_scores[\\'compound\\'])\\n\\nprint(m)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Assuming 'data' contains your list of text data\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "m={}\n",
    "\n",
    "count=0\n",
    "for sentence in data_books:\n",
    "    count+=1\n",
    "    sentiment_scores = sia.polarity_scores(sentence)\n",
    "    # The 'compound' score can help determine overall sentiment\n",
    "    m[sentence]=sentiment_scores\n",
    "    print(list(os.walk(data_folder_books[count])), \":\", sentiment_scores['compound'])\n",
    "\n",
    "print(m)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dffc1916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : 0.9983\n",
      "text : 0.9884\n",
      "text : -0.9419\n",
      "text : 0.9303\n",
      "text : 0.9984\n",
      "text : 0.6412\n",
      "text : 0.9667\n",
      "text : 0.9973\n",
      "text : 0.9998\n",
      "text : 0.9997\n",
      "text : 0.9963\n",
      "text : 0.9986\n",
      "text : 0.9952\n",
      "text : 0.9996\n",
      "text : 0.999\n",
      "text : -0.25\n",
      "text : 0.9974\n",
      "text : 0.9886\n",
      "text : 0.9967\n",
      "text : 0.9998\n",
      "text : 0.997\n",
      "text : 0.9926\n",
      "text : 0.8462\n",
      "text : 0.9973\n",
      "text : 0.9993\n",
      "text : 0.9925\n",
      "text : 0.9985\n",
      "text : 0.9948\n",
      "text : -0.9885\n",
      "text : 0.9957\n",
      "text : 0.9974\n",
      "text : 0.9995\n",
      "text : 0.9986\n",
      "text : 0.9932\n",
      "text : 0.9983\n",
      "text : 0.997\n",
      "text : 0.0008\n",
      "text : 0.9998\n",
      "text : 0.7779\n",
      "text : 0.9995\n",
      "text : 0.9997\n",
      "text : 0.3639\n",
      "text : -0.982\n",
      "text : 0.9972\n",
      "text : -0.9897\n",
      "text : 0.9794\n",
      "text : 0.9663\n",
      "text : 0.9878\n",
      "text : 0.9987\n",
      "text : 0.9739\n"
     ]
    }
   ],
   "source": [
    "for sentence in data_cars:\n",
    "    sentiment_scores = sia.polarity_scores(sentence)\n",
    "    # The 'compound' score can help determine overall sentiment\n",
    "    print(\"text\", \":\", sentiment_scores['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "571c8016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : 0.7375\n",
      "text : -0.25\n",
      "text : 0.9911\n",
      "text : 0.9745\n",
      "text : 0.9966\n",
      "text : 0.9799\n",
      "text : 0.6761\n",
      "text : 0.8779\n",
      "text : 0.9944\n",
      "text : 0.999\n",
      "text : 0.9971\n",
      "text : 0.9911\n",
      "text : 0.9855\n",
      "text : 0.9992\n",
      "text : 0.9974\n",
      "text : 0.9955\n",
      "text : 0.9387\n",
      "text : 0.98\n",
      "text : 0.999\n",
      "text : 0.9984\n",
      "text : 0.996\n",
      "text : 0.9958\n",
      "text : 0.9962\n",
      "text : 0.9977\n",
      "text : 0.9453\n",
      "text : -0.7278\n",
      "text : 0.9958\n",
      "text : 0.9943\n",
      "text : 0.9862\n",
      "text : 0.7089\n",
      "text : 0.9995\n",
      "text : 0.9965\n",
      "text : 0.8979\n",
      "text : 0.8818\n",
      "text : 0.9998\n",
      "text : 0.9993\n",
      "text : 0.9492\n",
      "text : 0.9954\n",
      "text : 0.8519\n",
      "text : 0.9651\n",
      "text : 0.9981\n",
      "text : 0.9073\n",
      "text : -0.9149\n",
      "text : 0.996\n",
      "text : 0.5553\n",
      "text : 0.9863\n",
      "text : 0.9389\n",
      "text : 0.8297\n",
      "text : 0.7835\n",
      "text : 0.3382\n"
     ]
    }
   ],
   "source": [
    "for sentence in data_cook:\n",
    "    sentiment_scores = sia.polarity_scores(sentence)\n",
    "    # The 'compound' score can help determine overall sentiment\n",
    "    print(\"text\", \":\", sentiment_scores['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b111628e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : -0.9382\n",
      "text : -0.9926\n",
      "text : 0.7205\n",
      "text : 0.8272\n",
      "text : 0.991\n",
      "text : 0.9839\n",
      "text : 0.778\n",
      "text : 0.7785\n",
      "text : 0.9729\n",
      "text : 0.9668\n",
      "text : 0.9488\n",
      "text : 0.9993\n",
      "text : 0.9941\n",
      "text : 0.9975\n",
      "text : 0.9975\n",
      "text : 0.9945\n",
      "text : 0.1157\n",
      "text : 0.9963\n",
      "text : 0.9976\n",
      "text : 0.9914\n",
      "text : 0.9878\n",
      "text : 0.995\n",
      "text : 0.999\n",
      "text : 0.9985\n",
      "text : 0.9987\n",
      "text : -0.3034\n",
      "text : 1.0\n",
      "text : 0.997\n",
      "text : 0.9781\n",
      "text : 0.598\n",
      "text : 0.9996\n",
      "text : 0.991\n",
      "text : 0.9989\n",
      "text : 0.6476\n",
      "text : 0.998\n",
      "text : 0.9996\n",
      "text : -0.9019\n",
      "text : 0.9967\n",
      "text : -0.9777\n",
      "text : 0.9824\n",
      "text : 0.9903\n",
      "text : 0.9675\n",
      "text : 0.9523\n",
      "text : 0.9808\n",
      "text : 0.9703\n",
      "text : 0.7638\n",
      "text : 0.0662\n",
      "text : -0.9879\n",
      "text : 0.9995\n",
      "text : 0.9998\n"
     ]
    }
   ],
   "source": [
    "for sentence in data_comps:\n",
    "    sentiment_scores = sia.polarity_scores(sentence)\n",
    "    # The 'compound' score can help determine overall sentiment\n",
    "    print(\"text\", \":\", sentiment_scores['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30dfb68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : 0.9629\n",
      "text : 0.9971\n",
      "text : -0.9761\n",
      "text : 0.9874\n",
      "text : 0.7628\n",
      "text : 0.9346\n",
      "text : 0.9907\n",
      "text : 0.9965\n",
      "text : 0.9947\n",
      "text : 0.9982\n",
      "text : 0.9963\n",
      "text : 0.9668\n",
      "text : 0.9989\n",
      "text : 0.9991\n",
      "text : 0.9352\n",
      "text : 0.9987\n",
      "text : 0.6961\n",
      "text : 0.9997\n",
      "text : 0.9964\n",
      "text : 0.9972\n",
      "text : 0.9989\n",
      "text : 0.9994\n",
      "text : 0.9969\n",
      "text : 0.999\n",
      "text : 0.9997\n",
      "text : 0.9199\n",
      "text : 0.9964\n",
      "text : 0.9979\n",
      "text : 0.9947\n",
      "text : 0.9815\n",
      "text : 0.9944\n",
      "text : 0.9997\n",
      "text : 0.9997\n",
      "text : 0.8393\n",
      "text : 0.9995\n",
      "text : 0.9993\n",
      "text : 0.991\n",
      "text : 0.9988\n",
      "text : 0.9609\n",
      "text : 0.9994\n",
      "text : 0.9991\n",
      "text : 0.9969\n",
      "text : 0.998\n",
      "text : -0.5333\n",
      "text : 0.9465\n",
      "text : 0.9808\n",
      "text : 0.6788\n",
      "text : 0.9967\n",
      "text : 0.9862\n",
      "text : 0.9669\n"
     ]
    }
   ],
   "source": [
    "for sentence in data_hotel:\n",
    "    sentiment_scores = sia.polarity_scores(sentence)\n",
    "    # The 'compound' score can help determine overall sentiment\n",
    "    print(\"text\", \":\", sentiment_scores['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cb6b8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : 0.996\n",
      "text : 0.991\n",
      "text : 0.9226\n",
      "text : 0.9985\n",
      "text : 0.978\n",
      "text : 0.0\n",
      "text : -0.9709\n",
      "text : 0.9927\n",
      "text : 0.9809\n",
      "text : 0.999\n",
      "text : 0.9489\n",
      "text : 0.9375\n",
      "text : 0.9882\n",
      "text : 0.9649\n",
      "text : 0.9996\n",
      "text : 0.9245\n",
      "text : 0.9934\n",
      "text : 0.9269\n",
      "text : 0.9956\n",
      "text : 0.9993\n",
      "text : 0.9981\n",
      "text : -0.4728\n",
      "text : 0.9967\n",
      "text : 0.968\n",
      "text : 0.9949\n",
      "text : 0.9972\n",
      "text : 0.9961\n",
      "text : 0.9991\n",
      "text : 0.9991\n",
      "text : -0.9726\n",
      "text : 0.999\n",
      "text : 0.9539\n",
      "text : 0.9889\n",
      "text : 0.9993\n",
      "text : 0.9868\n",
      "text : 0.9515\n",
      "text : 0.989\n",
      "text : 0.997\n",
      "text : 0.9924\n",
      "text : 0.9868\n",
      "text : 0.9993\n",
      "text : 0.8573\n",
      "text : -0.9977\n",
      "text : -0.9971\n",
      "text : 0.9943\n",
      "text : -0.9466\n",
      "text : -0.1085\n",
      "text : -0.998\n",
      "text : -0.9938\n",
      "text : -0.8555\n",
      "text : 0.5897\n",
      "text : -0.6843\n",
      "text : 0.9747\n",
      "text : 0.991\n",
      "text : 0.9226\n",
      "text : 0.9985\n",
      "text : 0.978\n",
      "text : -0.9709\n",
      "text : 0.9927\n",
      "text : 0.9809\n",
      "text : 0.999\n",
      "text : 0.9489\n",
      "text : 0.9375\n",
      "text : 0.9882\n",
      "text : 0.9649\n",
      "text : 0.9996\n",
      "text : 0.9245\n",
      "text : 0.9934\n",
      "text : 0.9269\n",
      "text : 0.9956\n",
      "text : 0.9993\n",
      "text : 0.9981\n",
      "text : -0.4728\n",
      "text : 0.9967\n",
      "text : 0.968\n",
      "text : 0.9949\n",
      "text : 0.9972\n",
      "text : 0.9961\n",
      "text : 0.9991\n",
      "text : 0.9991\n",
      "text : -0.9726\n",
      "text : 0.999\n",
      "text : 0.9539\n",
      "text : 0.9889\n",
      "text : 0.9993\n",
      "text : 0.9868\n",
      "text : 0.9515\n",
      "text : 0.989\n",
      "text : 0.997\n",
      "text : 0.9924\n",
      "text : 0.9868\n",
      "text : 0.9993\n",
      "text : 0.8573\n",
      "text : -0.9977\n",
      "text : -0.9971\n",
      "text : 0.8881\n",
      "text : -0.9466\n",
      "text : -0.1085\n",
      "text : -0.998\n",
      "text : -0.9938\n",
      "text : -0.8555\n",
      "text : -0.6843\n"
     ]
    }
   ],
   "source": [
    "for sentence in data_movie:\n",
    "    sentiment_scores = sia.polarity_scores(sentence)\n",
    "    # The 'compound' score can help determine overall sentiment\n",
    "    print(\"text\", \":\", sentiment_scores['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52daa105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : 0.992\n",
      "text : 0.9591\n",
      "text : 0.9975\n",
      "text : 0.9986\n",
      "text : 0.9997\n",
      "text : 0.969\n",
      "text : -0.4399\n",
      "text : 0.9979\n",
      "text : 0.9986\n",
      "text : 0.9947\n",
      "text : -0.722\n",
      "text : 0.9987\n",
      "text : 0.9996\n",
      "text : 0.9973\n",
      "text : 0.9934\n",
      "text : 0.9842\n",
      "text : 0.9978\n",
      "text : 0.9988\n",
      "text : 0.9972\n",
      "text : 0.9983\n",
      "text : 0.9981\n",
      "text : 0.8146\n",
      "text : 0.9531\n",
      "text : 0.9957\n",
      "text : 0.9852\n",
      "text : 0.9645\n",
      "text : 0.9325\n",
      "text : 0.9885\n",
      "text : 0.999\n",
      "text : -0.1007\n",
      "text : 0.4521\n",
      "text : 0.9995\n",
      "text : 0.954\n",
      "text : 0.8555\n",
      "text : 0.9982\n",
      "text : 0.9973\n",
      "text : -0.9987\n",
      "text : 0.9894\n",
      "text : -0.5864\n",
      "text : 0.9995\n",
      "text : 0.9996\n",
      "text : 0.7248\n",
      "text : 0.989\n",
      "text : 0.992\n",
      "text : -0.8352\n",
      "text : 0.9646\n",
      "text : -0.9933\n",
      "text : 0.8116\n",
      "text : -0.9094\n",
      "text : -0.4557\n"
     ]
    }
   ],
   "source": [
    "for sentence in data_music:\n",
    "    sentiment_scores = sia.polarity_scores(sentence)\n",
    "    # The 'compound' score can help determine overall sentiment\n",
    "    print(\"text\", \":\", sentiment_scores['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22adce4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : 0.9839\n",
      "text : 0.3455\n",
      "text : -0.9451\n",
      "text : 0.5351\n",
      "text : -0.6705\n",
      "text : 0.989\n",
      "text : 0.9243\n",
      "text : 0.9856\n",
      "text : 0.9603\n",
      "text : 0.9905\n",
      "text : 0.9962\n",
      "text : -0.378\n",
      "text : 0.9404\n",
      "text : 0.9528\n",
      "text : 0.9658\n",
      "text : 0.9916\n",
      "text : 0.9943\n",
      "text : 0.982\n",
      "text : 0.9989\n",
      "text : 0.9869\n",
      "text : 0.9697\n",
      "text : 0.9909\n",
      "text : 0.9896\n",
      "text : 0.9937\n",
      "text : 0.9856\n",
      "text : 0.8462\n",
      "text : 0.9813\n",
      "text : 0.9929\n",
      "text : -0.2737\n",
      "text : 0.6222\n",
      "text : 0.9775\n",
      "text : 0.9554\n",
      "text : 0.743\n",
      "text : 0.2241\n",
      "text : 0.9714\n",
      "text : 0.9982\n",
      "text : -0.7391\n",
      "text : 0.5695\n",
      "text : 0.7876\n",
      "text : 0.9696\n",
      "text : 0.9995\n",
      "text : -0.9206\n",
      "text : 0.8804\n",
      "text : -0.7872\n",
      "text : -0.2827\n",
      "text : -0.7082\n",
      "text : -0.8326\n",
      "text : 0.3612\n",
      "text : 0.9304\n",
      "text : -0.5526\n"
     ]
    }
   ],
   "source": [
    "for sentence in data_phone:\n",
    "    sentiment_scores = sia.polarity_scores(sentence)\n",
    "    # The 'compound' score can help determine overall sentiment\n",
    "    print(\"text\", \":\", sentiment_scores['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b79d5a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : 0.9839\n",
      "text : 0.3455\n",
      "text : -0.9451\n",
      "text : 0.5351\n",
      "text : -0.6705\n",
      "text : 0.989\n",
      "text : 0.9243\n",
      "text : 0.9856\n",
      "text : 0.9603\n",
      "text : 0.9905\n",
      "text : 0.9962\n",
      "text : -0.378\n",
      "text : 0.9404\n",
      "text : 0.9528\n",
      "text : 0.9658\n",
      "text : 0.9916\n",
      "text : 0.9943\n",
      "text : 0.982\n",
      "text : 0.9989\n",
      "text : 0.9869\n",
      "text : 0.9697\n",
      "text : 0.9909\n",
      "text : 0.9896\n",
      "text : 0.9937\n",
      "text : 0.9856\n",
      "text : 0.8462\n",
      "text : 0.9813\n",
      "text : 0.9929\n",
      "text : -0.2737\n",
      "text : 0.6222\n",
      "text : 0.9775\n",
      "text : 0.9554\n",
      "text : 0.743\n",
      "text : 0.2241\n",
      "text : 0.9714\n",
      "text : 0.9982\n",
      "text : -0.7391\n",
      "text : 0.5695\n",
      "text : 0.7876\n",
      "text : 0.9696\n",
      "text : 0.9995\n",
      "text : -0.9206\n",
      "text : 0.8804\n",
      "text : -0.7872\n",
      "text : -0.2827\n",
      "text : -0.7082\n",
      "text : -0.8326\n",
      "text : 0.3612\n",
      "text : 0.9304\n",
      "text : -0.5526\n"
     ]
    }
   ],
   "source": [
    "for sentence in data_phone:\n",
    "    sentiment_scores = sia.polarity_scores(sentence)\n",
    "    #The 'compound' score can help determine overall sentiment\n",
    "    print(\"text\", \":\", sentiment_scores['compound'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93980155",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'dict' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-7afda693982b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0msentiment_scores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mpositive_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnegative_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'dict' and 'int'"
     ]
    }
   ],
   "source": [
    "if sentiment_scores > 0:\n",
    "    positive_files.append((file_name, file_content))\n",
    "else:\n",
    "    negative_files.append((file_name, file_content))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279afbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
